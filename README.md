# Banana Navigation


## Environment Details


In this project, we train an agent to navigate (and collect bananas) in a large, square world. A reward of +1 is provided for collecting a yellow banana, and a reward of -1 is provided for collecting a blue banana. As such, the agent must collect yellow bananas as much as possible while avoiding the blue ones.

The state space has 37 dimensions and contains the agent's velocity, along with ray-based perception of objects around the agent's forward direction:

Given this information, the agent has to learn how to best select actions. Four discrete actions are available :

* `0` move forward
* `1` move backward
* `2` turn left
* `3` turn right. 
